{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport { eye, linalg, mul, ones, randomUniform, scalar, serialization, tidy, transpose, truncatedNormal, zeros } from '@tensorflow/tfjs-core';\nimport * as K from './backend/tfjs_backend';\nimport { checkDataFormat } from './common';\nimport { NotImplementedError, ValueError } from './errors';\nimport { VALID_DISTRIBUTION_VALUES, VALID_FAN_MODE_VALUES } from './keras_format/initializer_config';\nimport { checkStringTypeUnionValue, deserializeKerasObject, serializeKerasObject } from './utils/generic_utils';\nimport { arrayProd } from './utils/math_utils';\nexport function checkFanMode(value) {\n  checkStringTypeUnionValue(VALID_FAN_MODE_VALUES, 'FanMode', value);\n}\nexport function checkDistribution(value) {\n  checkStringTypeUnionValue(VALID_DISTRIBUTION_VALUES, 'Distribution', value);\n}\n/**\n * Initializer base class.\n *\n * @doc {\n *   heading: 'Initializers', subheading: 'Classes', namespace: 'initializers'}\n */\nexport class Initializer extends serialization.Serializable {\n  fromConfigUsesCustomObjects() {\n    return false;\n  }\n  getConfig() {\n    return {};\n  }\n}\nexport class Zeros extends Initializer {\n  apply(shape, dtype) {\n    return zeros(shape, dtype);\n  }\n}\n/** @nocollapse */\nZeros.className = 'Zeros';\nserialization.registerClass(Zeros);\nexport class Ones extends Initializer {\n  apply(shape, dtype) {\n    return ones(shape, dtype);\n  }\n}\n/** @nocollapse */\nOnes.className = 'Ones';\nserialization.registerClass(Ones);\nexport class Constant extends Initializer {\n  constructor(args) {\n    super();\n    if (typeof args !== 'object') {\n      throw new ValueError(`Expected argument of type ConstantConfig but got ${args}`);\n    }\n    if (args.value === undefined) {\n      throw new ValueError(`config must have value set but got ${args}`);\n    }\n    this.value = args.value;\n  }\n  apply(shape, dtype) {\n    return tidy(() => mul(scalar(this.value), ones(shape, dtype)));\n  }\n  getConfig() {\n    return {\n      value: this.value\n    };\n  }\n}\n/** @nocollapse */\nConstant.className = 'Constant';\nserialization.registerClass(Constant);\nexport class RandomUniform extends Initializer {\n  constructor(args) {\n    super();\n    this.DEFAULT_MINVAL = -0.05;\n    this.DEFAULT_MAXVAL = 0.05;\n    this.minval = args.minval || this.DEFAULT_MINVAL;\n    this.maxval = args.maxval || this.DEFAULT_MAXVAL;\n    this.seed = args.seed;\n  }\n  apply(shape, dtype) {\n    return randomUniform(shape, this.minval, this.maxval, dtype, this.seed);\n  }\n  getConfig() {\n    return {\n      minval: this.minval,\n      maxval: this.maxval,\n      seed: this.seed\n    };\n  }\n}\n/** @nocollapse */\nRandomUniform.className = 'RandomUniform';\nserialization.registerClass(RandomUniform);\nexport class RandomNormal extends Initializer {\n  constructor(args) {\n    super();\n    this.DEFAULT_MEAN = 0.;\n    this.DEFAULT_STDDEV = 0.05;\n    this.mean = args.mean || this.DEFAULT_MEAN;\n    this.stddev = args.stddev || this.DEFAULT_STDDEV;\n    this.seed = args.seed;\n  }\n  apply(shape, dtype) {\n    dtype = dtype || 'float32';\n    if (dtype !== 'float32' && dtype !== 'int32') {\n      throw new NotImplementedError(`randomNormal does not support dType ${dtype}.`);\n    }\n    return K.randomNormal(shape, this.mean, this.stddev, dtype, this.seed);\n  }\n  getConfig() {\n    return {\n      mean: this.mean,\n      stddev: this.stddev,\n      seed: this.seed\n    };\n  }\n}\n/** @nocollapse */\nRandomNormal.className = 'RandomNormal';\nserialization.registerClass(RandomNormal);\nexport class TruncatedNormal extends Initializer {\n  constructor(args) {\n    super();\n    this.DEFAULT_MEAN = 0.;\n    this.DEFAULT_STDDEV = 0.05;\n    this.mean = args.mean || this.DEFAULT_MEAN;\n    this.stddev = args.stddev || this.DEFAULT_STDDEV;\n    this.seed = args.seed;\n  }\n  apply(shape, dtype) {\n    dtype = dtype || 'float32';\n    if (dtype !== 'float32' && dtype !== 'int32') {\n      throw new NotImplementedError(`truncatedNormal does not support dType ${dtype}.`);\n    }\n    return truncatedNormal(shape, this.mean, this.stddev, dtype, this.seed);\n  }\n  getConfig() {\n    return {\n      mean: this.mean,\n      stddev: this.stddev,\n      seed: this.seed\n    };\n  }\n}\n/** @nocollapse */\nTruncatedNormal.className = 'TruncatedNormal';\nserialization.registerClass(TruncatedNormal);\nexport class Identity extends Initializer {\n  constructor(args) {\n    super();\n    this.gain = args.gain != null ? args.gain : 1.0;\n  }\n  apply(shape, dtype) {\n    return tidy(() => {\n      if (shape.length !== 2 || shape[0] !== shape[1]) {\n        throw new ValueError('Identity matrix initializer can only be used for' + ' 2D square matrices.');\n      } else {\n        return mul(this.gain, eye(shape[0]));\n      }\n    });\n  }\n  getConfig() {\n    return {\n      gain: this.gain\n    };\n  }\n}\n/** @nocollapse */\nIdentity.className = 'Identity';\nserialization.registerClass(Identity);\n/**\n * Computes the number of input and output units for a weight shape.\n * @param shape Shape of weight.\n * @param dataFormat data format to use for convolution kernels.\n *   Note that all kernels in Keras are standardized on the\n *   CHANNEL_LAST ordering (even when inputs are set to CHANNEL_FIRST).\n * @return An length-2 array: fanIn, fanOut.\n */\nfunction computeFans(shape) {\n  let dataFormat = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 'channelsLast';\n  let fanIn;\n  let fanOut;\n  checkDataFormat(dataFormat);\n  if (shape.length === 2) {\n    fanIn = shape[0];\n    fanOut = shape[1];\n  } else if ([3, 4, 5].indexOf(shape.length) !== -1) {\n    if (dataFormat === 'channelsFirst') {\n      const receptiveFieldSize = arrayProd(shape, 2);\n      fanIn = shape[1] * receptiveFieldSize;\n      fanOut = shape[0] * receptiveFieldSize;\n    } else if (dataFormat === 'channelsLast') {\n      const receptiveFieldSize = arrayProd(shape, 0, shape.length - 2);\n      fanIn = shape[shape.length - 2] * receptiveFieldSize;\n      fanOut = shape[shape.length - 1] * receptiveFieldSize;\n    }\n  } else {\n    const shapeProd = arrayProd(shape);\n    fanIn = Math.sqrt(shapeProd);\n    fanOut = Math.sqrt(shapeProd);\n  }\n  return [fanIn, fanOut];\n}\nexport class VarianceScaling extends Initializer {\n  /**\n   * Constructor of VarianceScaling.\n   * @throws ValueError for invalid value in scale.\n   */\n  constructor(args) {\n    super();\n    if (args.scale < 0.0) {\n      throw new ValueError(`scale must be a positive float. Got: ${args.scale}`);\n    }\n    this.scale = args.scale == null ? 1.0 : args.scale;\n    this.mode = args.mode == null ? 'fanIn' : args.mode;\n    checkFanMode(this.mode);\n    this.distribution = args.distribution == null ? 'normal' : args.distribution;\n    checkDistribution(this.distribution);\n    this.seed = args.seed;\n  }\n  apply(shape, dtype) {\n    const fans = computeFans(shape);\n    const fanIn = fans[0];\n    const fanOut = fans[1];\n    let scale = this.scale;\n    if (this.mode === 'fanIn') {\n      scale /= Math.max(1, fanIn);\n    } else if (this.mode === 'fanOut') {\n      scale /= Math.max(1, fanOut);\n    } else {\n      scale /= Math.max(1, (fanIn + fanOut) / 2);\n    }\n    if (this.distribution === 'normal') {\n      const stddev = Math.sqrt(scale);\n      dtype = dtype || 'float32';\n      if (dtype !== 'float32' && dtype !== 'int32') {\n        throw new NotImplementedError(`${this.getClassName()} does not support dType ${dtype}.`);\n      }\n      return truncatedNormal(shape, 0, stddev, dtype, this.seed);\n    } else {\n      const limit = Math.sqrt(3 * scale);\n      return randomUniform(shape, -limit, limit, dtype, this.seed);\n    }\n  }\n  getConfig() {\n    return {\n      scale: this.scale,\n      mode: this.mode,\n      distribution: this.distribution,\n      seed: this.seed\n    };\n  }\n}\n/** @nocollapse */\nVarianceScaling.className = 'VarianceScaling';\nserialization.registerClass(VarianceScaling);\nexport class GlorotUniform extends VarianceScaling {\n  /**\n   * Constructor of GlorotUniform\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  constructor(args) {\n    super({\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n  getClassName() {\n    // In Python Keras, GlorotUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\n/** @nocollapse */\nGlorotUniform.className = 'GlorotUniform';\nserialization.registerClass(GlorotUniform);\nexport class GlorotNormal extends VarianceScaling {\n  /**\n   * Constructor of GlorotNormal.\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  constructor(args) {\n    super({\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n  getClassName() {\n    // In Python Keras, GlorotNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\n/** @nocollapse */\nGlorotNormal.className = 'GlorotNormal';\nserialization.registerClass(GlorotNormal);\nexport class HeNormal extends VarianceScaling {\n  constructor(args) {\n    super({\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n  getClassName() {\n    // In Python Keras, HeNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\n/** @nocollapse */\nHeNormal.className = 'HeNormal';\nserialization.registerClass(HeNormal);\nexport class HeUniform extends VarianceScaling {\n  constructor(args) {\n    super({\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n  getClassName() {\n    // In Python Keras, HeUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\n/** @nocollapse */\nHeUniform.className = 'HeUniform';\nserialization.registerClass(HeUniform);\nexport class LeCunNormal extends VarianceScaling {\n  constructor(args) {\n    super({\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n  getClassName() {\n    // In Python Keras, LeCunNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\n/** @nocollapse */\nLeCunNormal.className = 'LeCunNormal';\nserialization.registerClass(LeCunNormal);\nexport class LeCunUniform extends VarianceScaling {\n  constructor(args) {\n    super({\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n  getClassName() {\n    // In Python Keras, LeCunUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\n/** @nocollapse */\nLeCunUniform.className = 'LeCunUniform';\nserialization.registerClass(LeCunUniform);\nexport class Orthogonal extends Initializer {\n  constructor(args) {\n    super();\n    this.DEFAULT_GAIN = 1;\n    this.gain = args.gain == null ? this.DEFAULT_GAIN : args.gain;\n    this.seed = args.seed;\n    if (this.seed != null) {\n      throw new NotImplementedError('Random seed is not implemented for Orthogonal Initializer yet.');\n    }\n  }\n  apply(shape, dtype) {\n    return tidy(() => {\n      if (shape.length < 2) {\n        throw new NotImplementedError('Shape must be at least 2D.');\n      }\n      if (shape[0] * shape[1] > 2000) {\n        console.warn(`Orthogonal initializer is being called on a matrix with more ` + `than 2000 (${shape[0] * shape[1]}) elements: ` + `Slowness may result.`);\n      }\n      // TODO(cais): Add seed support.\n      const normalizedShape = shape[0] > shape[1] ? [shape[1], shape[0]] : shape;\n      const a = K.randomNormal(normalizedShape, 0, 1, 'float32');\n      let q = linalg.gramSchmidt(a);\n      if (shape[0] > shape[1]) {\n        q = transpose(q);\n      }\n      return mul(this.gain, q);\n    });\n  }\n  getConfig() {\n    return {\n      gain: this.gain,\n      seed: this.seed\n    };\n  }\n}\n/** @nocollapse */\nOrthogonal.className = 'Orthogonal';\nserialization.registerClass(Orthogonal);\n// Maps the JavaScript-like identifier keys to the corresponding registry\n// symbols.\nexport const INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP = {\n  'constant': 'Constant',\n  'glorotNormal': 'GlorotNormal',\n  'glorotUniform': 'GlorotUniform',\n  'heNormal': 'HeNormal',\n  'heUniform': 'HeUniform',\n  'identity': 'Identity',\n  'leCunNormal': 'LeCunNormal',\n  'leCunUniform': 'LeCunUniform',\n  'ones': 'Ones',\n  'orthogonal': 'Orthogonal',\n  'randomNormal': 'RandomNormal',\n  'randomUniform': 'RandomUniform',\n  'truncatedNormal': 'TruncatedNormal',\n  'varianceScaling': 'VarianceScaling',\n  'zeros': 'Zeros'\n};\nfunction deserializeInitializer(config) {\n  let customObjects = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  return deserializeKerasObject(config, serialization.SerializationMap.getMap().classNameMap, customObjects, 'initializer');\n}\nexport function serializeInitializer(initializer) {\n  return serializeKerasObject(initializer);\n}\nexport function getInitializer(identifier) {\n  if (typeof identifier === 'string') {\n    const className = identifier in INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ? INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] : identifier;\n    /* We have four 'helper' classes for common initializers that\n    all get serialized as 'VarianceScaling' and shouldn't go through\n    the deserializeInitializer pathway. */\n    if (className === 'GlorotNormal') {\n      return new GlorotNormal();\n    } else if (className === 'GlorotUniform') {\n      return new GlorotUniform();\n    } else if (className === 'HeNormal') {\n      return new HeNormal();\n    } else if (className === 'HeUniform') {\n      return new HeUniform();\n    } else if (className === 'LeCunNormal') {\n      return new LeCunNormal();\n    } else if (className === 'LeCunUniform') {\n      return new LeCunUniform();\n    } else {\n      const config = {};\n      config['className'] = className;\n      config['config'] = {};\n      return deserializeInitializer(config);\n    }\n  } else if (identifier instanceof Initializer) {\n    return identifier;\n  } else {\n    return deserializeInitializer(identifier);\n  }\n}","map":{"version":3,"mappings":"AAAA;;;;;;;;;AAUA,SAAkBA,GAAG,EAAEC,MAAM,EAAEC,GAAG,EAAEC,IAAI,EAAEC,aAAa,EAAEC,MAAM,EAAEC,aAAa,EAAoBC,IAAI,EAAEC,SAAS,EAAEC,eAAe,EAAEC,KAAK,QAAO,uBAAuB;AAEvK,OAAO,KAAKC,CAAC,MAAM,wBAAwB;AAC3C,SAAQC,eAAe,QAAO,UAAU;AACxC,SAAQC,mBAAmB,EAAEC,UAAU,QAAO,UAAU;AAExD,SAA+BC,yBAAyB,EAAEC,qBAAqB,QAAO,mCAAmC;AACzH,SAAQC,yBAAyB,EAAEC,sBAAsB,EAAEC,oBAAoB,QAAO,uBAAuB;AAC7G,SAAQC,SAAS,QAAO,oBAAoB;AAE5C,OAAM,SAAUC,YAAY,CAACC,KAAc;EACzCL,yBAAyB,CAACD,qBAAqB,EAAE,SAAS,EAAEM,KAAK,CAAC;AACpE;AAEA,OAAM,SAAUC,iBAAiB,CAACD,KAAc;EAC9CL,yBAAyB,CAACF,yBAAyB,EAAE,cAAc,EAAEO,KAAK,CAAC;AAC7E;AAEA;;;;;;AAMA,OAAM,MAAgBE,WAAY,SAAQlB,aAAa,CAACmB,YAAY;EAC3DC,2BAA2B;IAChC,OAAO,KAAK;EACd;EASAC,SAAS;IACP,OAAO,EAAE;EACX;;AAGF,OAAM,MAAOC,KAAM,SAAQJ,WAAW;EAIpCK,KAAK,CAACC,KAAY,EAAEC,KAAgB;IAClC,OAAOrB,KAAK,CAACoB,KAAK,EAAEC,KAAK,CAAC;EAC5B;;AALA;AACOH,eAAS,GAAG,OAAO;AAM5BtB,aAAa,CAAC0B,aAAa,CAACJ,KAAK,CAAC;AAElC,OAAM,MAAOK,IAAK,SAAQT,WAAW;EAInCK,KAAK,CAACC,KAAY,EAAEC,KAAgB;IAClC,OAAO5B,IAAI,CAAC2B,KAAK,EAAEC,KAAK,CAAC;EAC3B;;AALA;AACOE,cAAS,GAAG,MAAM;AAM3B3B,aAAa,CAAC0B,aAAa,CAACC,IAAI,CAAC;AAOjC,OAAM,MAAOC,QAAS,SAAQV,WAAW;EAIvCW,YAAYC,IAAkB;IAC5B,KAAK,EAAE;IACP,IAAI,OAAOA,IAAI,KAAK,QAAQ,EAAE;MAC5B,MAAM,IAAItB,UAAU,CAChB,oDAAoDsB,IAAI,EAAE,CAAC;;IAEjE,IAAIA,IAAI,CAACd,KAAK,KAAKe,SAAS,EAAE;MAC5B,MAAM,IAAIvB,UAAU,CAAC,sCAAsCsB,IAAI,EAAE,CAAC;;IAEpE,IAAI,CAACd,KAAK,GAAGc,IAAI,CAACd,KAAK;EACzB;EAEAO,KAAK,CAACC,KAAY,EAAEC,KAAgB;IAClC,OAAOxB,IAAI,CAAC,MAAML,GAAG,CAACG,MAAM,CAAC,IAAI,CAACiB,KAAK,CAAC,EAAEnB,IAAI,CAAC2B,KAAK,EAAEC,KAAK,CAAC,CAAC,CAAC;EAChE;EAESJ,SAAS;IAChB,OAAO;MACLL,KAAK,EAAE,IAAI,CAACA;KACb;EACH;;AAvBA;AACOY,kBAAS,GAAG,UAAU;AAwB/B5B,aAAa,CAAC0B,aAAa,CAACE,QAAQ,CAAC;AAWrC,OAAM,MAAOI,aAAc,SAAQd,WAAW;EAS5CW,YAAYC,IAAuB;IACjC,KAAK,EAAE;IAPA,mBAAc,GAAG,CAAC,IAAI;IACtB,mBAAc,GAAG,IAAI;IAO5B,IAAI,CAACG,MAAM,GAAGH,IAAI,CAACG,MAAM,IAAI,IAAI,CAACC,cAAc;IAChD,IAAI,CAACC,MAAM,GAAGL,IAAI,CAACK,MAAM,IAAI,IAAI,CAACC,cAAc;IAChD,IAAI,CAACC,IAAI,GAAGP,IAAI,CAACO,IAAI;EACvB;EAEAd,KAAK,CAACC,KAAY,EAAEC,KAAgB;IAClC,OAAO3B,aAAa,CAAC0B,KAAK,EAAE,IAAI,CAACS,MAAM,EAAE,IAAI,CAACE,MAAM,EAAEV,KAAK,EAAE,IAAI,CAACY,IAAI,CAAC;EACzE;EAEShB,SAAS;IAChB,OAAO;MAACY,MAAM,EAAE,IAAI,CAACA,MAAM;MAAEE,MAAM,EAAE,IAAI,CAACA,MAAM;MAAEE,IAAI,EAAE,IAAI,CAACA;IAAI,CAAC;EACpE;;AArBA;AACOL,uBAAS,GAAG,eAAe;AAsBpChC,aAAa,CAAC0B,aAAa,CAACM,aAAa,CAAC;AAW1C,OAAM,MAAOM,YAAa,SAAQpB,WAAW;EAS3CW,YAAYC,IAAsB;IAChC,KAAK,EAAE;IAPA,iBAAY,GAAG,EAAE;IACjB,mBAAc,GAAG,IAAI;IAO5B,IAAI,CAACS,IAAI,GAAGT,IAAI,CAACS,IAAI,IAAI,IAAI,CAACC,YAAY;IAC1C,IAAI,CAACC,MAAM,GAAGX,IAAI,CAACW,MAAM,IAAI,IAAI,CAACC,cAAc;IAChD,IAAI,CAACL,IAAI,GAAGP,IAAI,CAACO,IAAI;EACvB;EAEAd,KAAK,CAACC,KAAY,EAAEC,KAAgB;IAClCA,KAAK,GAAGA,KAAK,IAAI,SAAS;IAC1B,IAAIA,KAAK,KAAK,SAAS,IAAIA,KAAK,KAAK,OAAO,EAAE;MAC5C,MAAM,IAAIlB,mBAAmB,CACzB,uCAAuCkB,KAAK,GAAG,CAAC;;IAGtD,OAAOpB,CAAC,CAACsC,YAAY,CAACnB,KAAK,EAAE,IAAI,CAACe,IAAI,EAAE,IAAI,CAACE,MAAM,EAAEhB,KAAK,EAAE,IAAI,CAACY,IAAI,CAAC;EACxE;EAEShB,SAAS;IAChB,OAAO;MAACkB,IAAI,EAAE,IAAI,CAACA,IAAI;MAAEE,MAAM,EAAE,IAAI,CAACA,MAAM;MAAEJ,IAAI,EAAE,IAAI,CAACA;IAAI,CAAC;EAChE;;AA3BA;AACOC,sBAAS,GAAG,cAAc;AA4BnCtC,aAAa,CAAC0B,aAAa,CAACY,YAAY,CAAC;AAWzC,OAAM,MAAOM,eAAgB,SAAQ1B,WAAW;EAU9CW,YAAYC,IAAyB;IACnC,KAAK,EAAE;IAPA,iBAAY,GAAG,EAAE;IACjB,mBAAc,GAAG,IAAI;IAO5B,IAAI,CAACS,IAAI,GAAGT,IAAI,CAACS,IAAI,IAAI,IAAI,CAACC,YAAY;IAC1C,IAAI,CAACC,MAAM,GAAGX,IAAI,CAACW,MAAM,IAAI,IAAI,CAACC,cAAc;IAChD,IAAI,CAACL,IAAI,GAAGP,IAAI,CAACO,IAAI;EACvB;EAEAd,KAAK,CAACC,KAAY,EAAEC,KAAgB;IAClCA,KAAK,GAAGA,KAAK,IAAI,SAAS;IAC1B,IAAIA,KAAK,KAAK,SAAS,IAAIA,KAAK,KAAK,OAAO,EAAE;MAC5C,MAAM,IAAIlB,mBAAmB,CACzB,0CAA0CkB,KAAK,GAAG,CAAC;;IAEzD,OAAOtB,eAAe,CAACqB,KAAK,EAAE,IAAI,CAACe,IAAI,EAAE,IAAI,CAACE,MAAM,EAAEhB,KAAK,EAAE,IAAI,CAACY,IAAI,CAAC;EACzE;EAEShB,SAAS;IAChB,OAAO;MAACkB,IAAI,EAAE,IAAI,CAACA,IAAI;MAAEE,MAAM,EAAE,IAAI,CAACA,MAAM;MAAEJ,IAAI,EAAE,IAAI,CAACA;IAAI,CAAC;EAChE;;AA3BA;AACOO,yBAAS,GAAG,iBAAiB;AA4BtC5C,aAAa,CAAC0B,aAAa,CAACkB,eAAe,CAAC;AAS5C,OAAM,MAAOC,QAAS,SAAQ3B,WAAW;EAIvCW,YAAYC,IAAkB;IAC5B,KAAK,EAAE;IACP,IAAI,CAACgB,IAAI,GAAGhB,IAAI,CAACgB,IAAI,IAAI,IAAI,GAAGhB,IAAI,CAACgB,IAAI,GAAG,GAAG;EACjD;EAEAvB,KAAK,CAACC,KAAY,EAAEC,KAAgB;IAClC,OAAOxB,IAAI,CAAC,MAAK;MACf,IAAIuB,KAAK,CAACuB,MAAM,KAAK,CAAC,IAAIvB,KAAK,CAAC,CAAC,CAAC,KAAKA,KAAK,CAAC,CAAC,CAAC,EAAE;QAC/C,MAAM,IAAIhB,UAAU,CAChB,kDAAkD,GAClD,sBAAsB,CAAC;OAC5B,MAAM;QACL,OAAOZ,GAAG,CAAC,IAAI,CAACkD,IAAI,EAAEpD,GAAG,CAAC8B,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;;IAExC,CAAC,CAAC;EACJ;EAESH,SAAS;IAChB,OAAO;MAACyB,IAAI,EAAE,IAAI,CAACA;IAAI,CAAC;EAC1B;;AAtBA;AACOD,kBAAS,GAAG,UAAU;AAuB/B7C,aAAa,CAAC0B,aAAa,CAACmB,QAAQ,CAAC;AAErC;;;;;;;;AAQA,SAASG,WAAW,CAChBxB,KAAY,EAAyC;EAAA,IAAvCyB,iFAAyB,cAAc;EACvD,IAAIC,KAAa;EACjB,IAAIC,MAAc;EAClB7C,eAAe,CAAC2C,UAAU,CAAC;EAC3B,IAAIzB,KAAK,CAACuB,MAAM,KAAK,CAAC,EAAE;IACtBG,KAAK,GAAG1B,KAAK,CAAC,CAAC,CAAC;IAChB2B,MAAM,GAAG3B,KAAK,CAAC,CAAC,CAAC;GAClB,MAAM,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC4B,OAAO,CAAC5B,KAAK,CAACuB,MAAM,CAAC,KAAK,CAAC,CAAC,EAAE;IACjD,IAAIE,UAAU,KAAK,eAAe,EAAE;MAClC,MAAMI,kBAAkB,GAAGvC,SAAS,CAACU,KAAK,EAAE,CAAC,CAAC;MAC9C0B,KAAK,GAAG1B,KAAK,CAAC,CAAC,CAAC,GAAG6B,kBAAkB;MACrCF,MAAM,GAAG3B,KAAK,CAAC,CAAC,CAAC,GAAG6B,kBAAkB;KACvC,MAAM,IAAIJ,UAAU,KAAK,cAAc,EAAE;MACxC,MAAMI,kBAAkB,GAAGvC,SAAS,CAACU,KAAK,EAAE,CAAC,EAAEA,KAAK,CAACuB,MAAM,GAAG,CAAC,CAAC;MAChEG,KAAK,GAAG1B,KAAK,CAACA,KAAK,CAACuB,MAAM,GAAG,CAAC,CAAC,GAAGM,kBAAkB;MACpDF,MAAM,GAAG3B,KAAK,CAACA,KAAK,CAACuB,MAAM,GAAG,CAAC,CAAC,GAAGM,kBAAkB;;GAExD,MAAM;IACL,MAAMC,SAAS,GAAGxC,SAAS,CAACU,KAAK,CAAC;IAClC0B,KAAK,GAAGK,IAAI,CAACC,IAAI,CAACF,SAAS,CAAC;IAC5BH,MAAM,GAAGI,IAAI,CAACC,IAAI,CAACF,SAAS,CAAC;;EAG/B,OAAO,CAACJ,KAAK,EAAEC,MAAM,CAAC;AACxB;AAgBA,OAAM,MAAOM,eAAgB,SAAQvC,WAAW;EAQ9C;;;;EAIAW,YAAYC,IAAyB;IACnC,KAAK,EAAE;IACP,IAAIA,IAAI,CAAC4B,KAAK,GAAG,GAAG,EAAE;MACpB,MAAM,IAAIlD,UAAU,CAChB,wCAAwCsB,IAAI,CAAC4B,KAAK,EAAE,CAAC;;IAE3D,IAAI,CAACA,KAAK,GAAG5B,IAAI,CAAC4B,KAAK,IAAI,IAAI,GAAG,GAAG,GAAG5B,IAAI,CAAC4B,KAAK;IAClD,IAAI,CAACC,IAAI,GAAG7B,IAAI,CAAC6B,IAAI,IAAI,IAAI,GAAG,OAAO,GAAG7B,IAAI,CAAC6B,IAAI;IACnD5C,YAAY,CAAC,IAAI,CAAC4C,IAAI,CAAC;IACvB,IAAI,CAACC,YAAY,GACb9B,IAAI,CAAC8B,YAAY,IAAI,IAAI,GAAG,QAAQ,GAAG9B,IAAI,CAAC8B,YAAY;IAC5D3C,iBAAiB,CAAC,IAAI,CAAC2C,YAAY,CAAC;IACpC,IAAI,CAACvB,IAAI,GAAGP,IAAI,CAACO,IAAI;EACvB;EAEAd,KAAK,CAACC,KAAY,EAAEC,KAAgB;IAClC,MAAMoC,IAAI,GAAGb,WAAW,CAACxB,KAAK,CAAC;IAC/B,MAAM0B,KAAK,GAAGW,IAAI,CAAC,CAAC,CAAC;IACrB,MAAMV,MAAM,GAAGU,IAAI,CAAC,CAAC,CAAC;IACtB,IAAIH,KAAK,GAAG,IAAI,CAACA,KAAK;IACtB,IAAI,IAAI,CAACC,IAAI,KAAK,OAAO,EAAE;MACzBD,KAAK,IAAIH,IAAI,CAACO,GAAG,CAAC,CAAC,EAAEZ,KAAK,CAAC;KAC5B,MAAM,IAAI,IAAI,CAACS,IAAI,KAAK,QAAQ,EAAE;MACjCD,KAAK,IAAIH,IAAI,CAACO,GAAG,CAAC,CAAC,EAAEX,MAAM,CAAC;KAC7B,MAAM;MACLO,KAAK,IAAIH,IAAI,CAACO,GAAG,CAAC,CAAC,EAAE,CAACZ,KAAK,GAAGC,MAAM,IAAI,CAAC,CAAC;;IAG5C,IAAI,IAAI,CAACS,YAAY,KAAK,QAAQ,EAAE;MAClC,MAAMnB,MAAM,GAAGc,IAAI,CAACC,IAAI,CAACE,KAAK,CAAC;MAC/BjC,KAAK,GAAGA,KAAK,IAAI,SAAS;MAC1B,IAAIA,KAAK,KAAK,SAAS,IAAIA,KAAK,KAAK,OAAO,EAAE;QAC5C,MAAM,IAAIlB,mBAAmB,CACzB,GAAG,IAAI,CAACwD,YAAY,EAAE,2BAA2BtC,KAAK,GAAG,CAAC;;MAEhE,OAAOtB,eAAe,CAACqB,KAAK,EAAE,CAAC,EAAEiB,MAAM,EAAEhB,KAAK,EAAE,IAAI,CAACY,IAAI,CAAC;KAC3D,MAAM;MACL,MAAM2B,KAAK,GAAGT,IAAI,CAACC,IAAI,CAAC,CAAC,GAAGE,KAAK,CAAC;MAClC,OAAO5D,aAAa,CAAC0B,KAAK,EAAE,CAACwC,KAAK,EAAEA,KAAK,EAAEvC,KAAK,EAAE,IAAI,CAACY,IAAI,CAAC;;EAEhE;EAEShB,SAAS;IAChB,OAAO;MACLqC,KAAK,EAAE,IAAI,CAACA,KAAK;MACjBC,IAAI,EAAE,IAAI,CAACA,IAAI;MACfC,YAAY,EAAE,IAAI,CAACA,YAAY;MAC/BvB,IAAI,EAAE,IAAI,CAACA;KACZ;EACH;;AA5DA;AACOoB,yBAAS,GAAG,iBAAiB;AA6DtCzD,aAAa,CAAC0B,aAAa,CAAC+B,eAAe,CAAC;AAO5C,OAAM,MAAOQ,aAAc,SAAQR,eAAe;EAIhD;;;;;;;EAOA5B,YAAYC,IAA8B;IACxC,KAAK,CAAC;MACJ4B,KAAK,EAAE,GAAG;MACVC,IAAI,EAAE,QAAQ;MACdC,YAAY,EAAE,SAAS;MACvBvB,IAAI,EAAEP,IAAI,IAAI,IAAI,GAAG,IAAI,GAAGA,IAAI,CAACO;KAClC,CAAC;EACJ;EAES0B,YAAY;IACnB;IACA;IACA;IACA,OAAON,eAAe,CAACS,SAAS;EAClC;;AAxBA;AACgBD,uBAAS,GAAG,eAAe;AAyB7CjE,aAAa,CAAC0B,aAAa,CAACuC,aAAa,CAAC;AAE1C,OAAM,MAAOE,YAAa,SAAQV,eAAe;EAI/C;;;;;;;EAOA5B,YAAYC,IAA8B;IACxC,KAAK,CAAC;MACJ4B,KAAK,EAAE,GAAG;MACVC,IAAI,EAAE,QAAQ;MACdC,YAAY,EAAE,QAAQ;MACtBvB,IAAI,EAAEP,IAAI,IAAI,IAAI,GAAG,IAAI,GAAGA,IAAI,CAACO;KAClC,CAAC;EACJ;EAES0B,YAAY;IACnB;IACA;IACA;IACA,OAAON,eAAe,CAACS,SAAS;EAClC;;AAxBA;AACgBC,sBAAS,GAAG,cAAc;AAyB5CnE,aAAa,CAAC0B,aAAa,CAACyC,YAAY,CAAC;AAEzC,OAAM,MAAOC,QAAS,SAAQX,eAAe;EAI3C5B,YAAYC,IAA8B;IACxC,KAAK,CAAC;MACJ4B,KAAK,EAAE,GAAG;MACVC,IAAI,EAAE,OAAO;MACbC,YAAY,EAAE,QAAQ;MACtBvB,IAAI,EAAEP,IAAI,IAAI,IAAI,GAAG,IAAI,GAAGA,IAAI,CAACO;KAClC,CAAC;EACJ;EAES0B,YAAY;IACnB;IACA;IACA;IACA,OAAON,eAAe,CAACS,SAAS;EAClC;;AAjBA;AACgBE,kBAAS,GAAG,UAAU;AAkBxCpE,aAAa,CAAC0B,aAAa,CAAC0C,QAAQ,CAAC;AAErC,OAAM,MAAOC,SAAU,SAAQZ,eAAe;EAI5C5B,YAAYC,IAA8B;IACxC,KAAK,CAAC;MACJ4B,KAAK,EAAE,GAAG;MACVC,IAAI,EAAE,OAAO;MACbC,YAAY,EAAE,SAAS;MACvBvB,IAAI,EAAEP,IAAI,IAAI,IAAI,GAAG,IAAI,GAAGA,IAAI,CAACO;KAClC,CAAC;EACJ;EAES0B,YAAY;IACnB;IACA;IACA;IACA,OAAON,eAAe,CAACS,SAAS;EAClC;;AAjBA;AACgBG,mBAAS,GAAG,WAAW;AAkBzCrE,aAAa,CAAC0B,aAAa,CAAC2C,SAAS,CAAC;AAEtC,OAAM,MAAOC,WAAY,SAAQb,eAAe;EAI9C5B,YAAYC,IAA8B;IACxC,KAAK,CAAC;MACJ4B,KAAK,EAAE,GAAG;MACVC,IAAI,EAAE,OAAO;MACbC,YAAY,EAAE,QAAQ;MACtBvB,IAAI,EAAEP,IAAI,IAAI,IAAI,GAAG,IAAI,GAAGA,IAAI,CAACO;KAClC,CAAC;EACJ;EAES0B,YAAY;IACnB;IACA;IACA;IACA,OAAON,eAAe,CAACS,SAAS;EAClC;;AAjBA;AACgBI,qBAAS,GAAG,aAAa;AAkB3CtE,aAAa,CAAC0B,aAAa,CAAC4C,WAAW,CAAC;AAExC,OAAM,MAAOC,YAAa,SAAQd,eAAe;EAI/C5B,YAAYC,IAA8B;IACxC,KAAK,CAAC;MACJ4B,KAAK,EAAE,GAAG;MACVC,IAAI,EAAE,OAAO;MACbC,YAAY,EAAE,SAAS;MACvBvB,IAAI,EAAEP,IAAI,IAAI,IAAI,GAAG,IAAI,GAAGA,IAAI,CAACO;KAClC,CAAC;EACJ;EAES0B,YAAY;IACnB;IACA;IACA;IACA,OAAON,eAAe,CAACS,SAAS;EAClC;;AAjBA;AACgBK,sBAAS,GAAG,cAAc;AAkB5CvE,aAAa,CAAC0B,aAAa,CAAC6C,YAAY,CAAC;AASzC,OAAM,MAAOC,UAAW,SAAQtD,WAAW;EAOzCW,YAAYC,IAAqB;IAC/B,KAAK,EAAE;IALA,iBAAY,GAAG,CAAC;IAMvB,IAAI,CAACgB,IAAI,GAAGhB,IAAI,CAACgB,IAAI,IAAI,IAAI,GAAG,IAAI,CAAC2B,YAAY,GAAG3C,IAAI,CAACgB,IAAI;IAC7D,IAAI,CAACT,IAAI,GAAGP,IAAI,CAACO,IAAI;IAErB,IAAI,IAAI,CAACA,IAAI,IAAI,IAAI,EAAE;MACrB,MAAM,IAAI9B,mBAAmB,CACzB,gEAAgE,CAAC;;EAEzE;EAEAgB,KAAK,CAACC,KAAY,EAAEC,KAAgB;IAClC,OAAOxB,IAAI,CAAC,MAAK;MACf,IAAIuB,KAAK,CAACuB,MAAM,GAAG,CAAC,EAAE;QACpB,MAAM,IAAIxC,mBAAmB,CAAC,4BAA4B,CAAC;;MAE7D,IAAIiB,KAAK,CAAC,CAAC,CAAC,GAAGA,KAAK,CAAC,CAAC,CAAC,GAAG,IAAI,EAAE;QAC9BkD,OAAO,CAACC,IAAI,CACR,+DAA+D,GAC/D,cAAcnD,KAAK,CAAC,CAAC,CAAC,GAAGA,KAAK,CAAC,CAAC,CAAC,cAAc,GAC/C,sBAAsB,CAAC;;MAG7B;MACA,MAAMoD,eAAe,GACjBpD,KAAK,CAAC,CAAC,CAAC,GAAGA,KAAK,CAAC,CAAC,CAAC,GAAG,CAACA,KAAK,CAAC,CAAC,CAAC,EAAEA,KAAK,CAAC,CAAC,CAAC,CAAC,GAAGA,KAAK;MACtD,MAAMqD,CAAC,GAAGxE,CAAC,CAACsC,YAAY,CAACiC,eAAe,EAAE,CAAC,EAAE,CAAC,EAAE,SAAS,CAAa;MACtE,IAAIE,CAAC,GAAGnF,MAAM,CAACoF,WAAW,CAACF,CAAC,CAAa;MACzC,IAAIrD,KAAK,CAAC,CAAC,CAAC,GAAGA,KAAK,CAAC,CAAC,CAAC,EAAE;QACvBsD,CAAC,GAAG5E,SAAS,CAAC4E,CAAC,CAAC;;MAElB,OAAOlF,GAAG,CAAC,IAAI,CAACkD,IAAI,EAAEgC,CAAC,CAAC;IAC1B,CAAC,CAAC;EACJ;EAESzD,SAAS;IAChB,OAAO;MACLyB,IAAI,EAAE,IAAI,CAACA,IAAI;MACfT,IAAI,EAAE,IAAI,CAACA;KACZ;EACH;;AA9CA;AACOmC,oBAAS,GAAG,YAAY;AA+CjCxE,aAAa,CAAC0B,aAAa,CAAC8C,UAAU,CAAC;AAQvC;AACA;AACA,OAAO,MAAMQ,0CAA0C,GACD;EAChD,UAAU,EAAE,UAAU;EACtB,cAAc,EAAE,cAAc;EAC9B,eAAe,EAAE,eAAe;EAChC,UAAU,EAAE,UAAU;EACtB,WAAW,EAAE,WAAW;EACxB,UAAU,EAAE,UAAU;EACtB,aAAa,EAAE,aAAa;EAC5B,cAAc,EAAE,cAAc;EAC9B,MAAM,EAAE,MAAM;EACd,YAAY,EAAE,YAAY;EAC1B,cAAc,EAAE,cAAc;EAC9B,eAAe,EAAE,eAAe;EAChC,iBAAiB,EAAE,iBAAiB;EACpC,iBAAiB,EAAE,iBAAiB;EACpC,OAAO,EAAE;CACV;AAEL,SAASC,sBAAsB,CAC3BC,MAAgC,EACY;EAAA,IAA5CC,oFAA0C,EAAE;EAC9C,OAAOvE,sBAAsB,CACzBsE,MAAM,EAAElF,aAAa,CAACoF,gBAAgB,CAACC,MAAM,EAAE,CAACC,YAAY,EAC5DH,aAAa,EAAE,aAAa,CAAC;AACnC;AAEA,OAAM,SAAUI,oBAAoB,CAACC,WAAwB;EAE3D,OAAO3E,oBAAoB,CAAC2E,WAAW,CAAC;AAC1C;AAEA,OAAM,SAAUC,cAAc,CAACC,UACwB;EACrD,IAAI,OAAOA,UAAU,KAAK,QAAQ,EAAE;IAClC,MAAMxB,SAAS,GAAGwB,UAAU,IAAIV,0CAA0C,GACtEA,0CAA0C,CAACU,UAAU,CAAC,GACtDA,UAAU;IACd;;;IAGA,IAAIxB,SAAS,KAAK,cAAc,EAAE;MAChC,OAAO,IAAIC,YAAY,EAAE;KAC1B,MAAM,IAAID,SAAS,KAAK,eAAe,EAAE;MACxC,OAAO,IAAID,aAAa,EAAE;KAC3B,MAAM,IAAIC,SAAS,KAAK,UAAU,EAAE;MACnC,OAAO,IAAIE,QAAQ,EAAE;KACtB,MAAM,IAAIF,SAAS,KAAK,WAAW,EAAE;MACpC,OAAO,IAAIG,SAAS,EAAE;KACvB,MAAM,IAAIH,SAAS,KAAK,aAAa,EAAE;MACtC,OAAO,IAAII,WAAW,EAAE;KACzB,MAAM,IAAIJ,SAAS,KAAK,cAAc,EAAE;MACvC,OAAO,IAAIK,YAAY,EAAE;KAC1B,MAAM;MACL,MAAMW,MAAM,GAA6B,EAAE;MAC3CA,MAAM,CAAC,WAAW,CAAC,GAAGhB,SAAS;MAC/BgB,MAAM,CAAC,QAAQ,CAAC,GAAG,EAAE;MACrB,OAAOD,sBAAsB,CAACC,MAAM,CAAC;;GAExC,MAAM,IAAIQ,UAAU,YAAYxE,WAAW,EAAE;IAC5C,OAAOwE,UAAU;GAClB,MAAM;IACL,OAAOT,sBAAsB,CAACS,UAAU,CAAC;;AAE7C","names":["eye","linalg","mul","ones","randomUniform","scalar","serialization","tidy","transpose","truncatedNormal","zeros","K","checkDataFormat","NotImplementedError","ValueError","VALID_DISTRIBUTION_VALUES","VALID_FAN_MODE_VALUES","checkStringTypeUnionValue","deserializeKerasObject","serializeKerasObject","arrayProd","checkFanMode","value","checkDistribution","Initializer","Serializable","fromConfigUsesCustomObjects","getConfig","Zeros","apply","shape","dtype","registerClass","Ones","Constant","constructor","args","undefined","RandomUniform","minval","DEFAULT_MINVAL","maxval","DEFAULT_MAXVAL","seed","RandomNormal","mean","DEFAULT_MEAN","stddev","DEFAULT_STDDEV","randomNormal","TruncatedNormal","Identity","gain","length","computeFans","dataFormat","fanIn","fanOut","indexOf","receptiveFieldSize","shapeProd","Math","sqrt","VarianceScaling","scale","mode","distribution","fans","max","getClassName","limit","GlorotUniform","className","GlorotNormal","HeNormal","HeUniform","LeCunNormal","LeCunUniform","Orthogonal","DEFAULT_GAIN","console","warn","normalizedShape","a","q","gramSchmidt","INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP","deserializeInitializer","config","customObjects","SerializationMap","getMap","classNameMap","serializeInitializer","initializer","getInitializer","identifier"],"sources":["D:\\Do not touch hand on your face\\bo_tay_ra\\node_modules\\@tensorflow\\tfjs-layers\\src\\initializers.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport {DataType, eye, linalg, mul, ones, randomUniform, scalar, serialization, Tensor, Tensor2D, tidy, transpose, truncatedNormal, zeros} from '@tensorflow/tfjs-core';\n\nimport * as K from './backend/tfjs_backend';\nimport {checkDataFormat} from './common';\nimport {NotImplementedError, ValueError} from './errors';\nimport {DataFormat, Shape} from './keras_format/common';\nimport {Distribution, FanMode, VALID_DISTRIBUTION_VALUES, VALID_FAN_MODE_VALUES} from './keras_format/initializer_config';\nimport {checkStringTypeUnionValue, deserializeKerasObject, serializeKerasObject} from './utils/generic_utils';\nimport {arrayProd} from './utils/math_utils';\n\nexport function checkFanMode(value?: string): void {\n  checkStringTypeUnionValue(VALID_FAN_MODE_VALUES, 'FanMode', value);\n}\n\nexport function checkDistribution(value?: string): void {\n  checkStringTypeUnionValue(VALID_DISTRIBUTION_VALUES, 'Distribution', value);\n}\n\n/**\n * Initializer base class.\n *\n * @doc {\n *   heading: 'Initializers', subheading: 'Classes', namespace: 'initializers'}\n */\nexport abstract class Initializer extends serialization.Serializable {\n  public fromConfigUsesCustomObjects(): boolean {\n    return false;\n  }\n  /**\n   * Generate an initial value.\n   * @param shape\n   * @param dtype\n   * @return The init value.\n   */\n  abstract apply(shape: Shape, dtype?: DataType): Tensor;\n\n  getConfig(): serialization.ConfigDict {\n    return {};\n  }\n}\n\nexport class Zeros extends Initializer {\n  /** @nocollapse */\n  static className = 'Zeros';\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return zeros(shape, dtype);\n  }\n}\nserialization.registerClass(Zeros);\n\nexport class Ones extends Initializer {\n  /** @nocollapse */\n  static className = 'Ones';\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return ones(shape, dtype);\n  }\n}\nserialization.registerClass(Ones);\n\nexport interface ConstantArgs {\n  /** The value for each element in the variable. */\n  value: number;\n}\n\nexport class Constant extends Initializer {\n  /** @nocollapse */\n  static className = 'Constant';\n  private value: number;\n  constructor(args: ConstantArgs) {\n    super();\n    if (typeof args !== 'object') {\n      throw new ValueError(\n          `Expected argument of type ConstantConfig but got ${args}`);\n    }\n    if (args.value === undefined) {\n      throw new ValueError(`config must have value set but got ${args}`);\n    }\n    this.value = args.value;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return tidy(() => mul(scalar(this.value), ones(shape, dtype)));\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    return {\n      value: this.value,\n    };\n  }\n}\nserialization.registerClass(Constant);\n\nexport interface RandomUniformArgs {\n  /** Lower bound of the range of random values to generate. */\n  minval?: number;\n  /** Upper bound of the range of random values to generate. */\n  maxval?: number;\n  /** Used to seed the random generator. */\n  seed?: number;\n}\n\nexport class RandomUniform extends Initializer {\n  /** @nocollapse */\n  static className = 'RandomUniform';\n  readonly DEFAULT_MINVAL = -0.05;\n  readonly DEFAULT_MAXVAL = 0.05;\n  private minval: number;\n  private maxval: number;\n  private seed: number;\n\n  constructor(args: RandomUniformArgs) {\n    super();\n    this.minval = args.minval || this.DEFAULT_MINVAL;\n    this.maxval = args.maxval || this.DEFAULT_MAXVAL;\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return randomUniform(shape, this.minval, this.maxval, dtype, this.seed);\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    return {minval: this.minval, maxval: this.maxval, seed: this.seed};\n  }\n}\nserialization.registerClass(RandomUniform);\n\nexport interface RandomNormalArgs {\n  /** Mean of the random values to generate. */\n  mean?: number;\n  /** Standard deviation of the random values to generate. */\n  stddev?: number;\n  /** Used to seed the random generator. */\n  seed?: number;\n}\n\nexport class RandomNormal extends Initializer {\n  /** @nocollapse */\n  static className = 'RandomNormal';\n  readonly DEFAULT_MEAN = 0.;\n  readonly DEFAULT_STDDEV = 0.05;\n  private mean: number;\n  private stddev: number;\n  private seed: number;\n\n  constructor(args: RandomNormalArgs) {\n    super();\n    this.mean = args.mean || this.DEFAULT_MEAN;\n    this.stddev = args.stddev || this.DEFAULT_STDDEV;\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    dtype = dtype || 'float32';\n    if (dtype !== 'float32' && dtype !== 'int32') {\n      throw new NotImplementedError(\n          `randomNormal does not support dType ${dtype}.`);\n    }\n\n    return K.randomNormal(shape, this.mean, this.stddev, dtype, this.seed);\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    return {mean: this.mean, stddev: this.stddev, seed: this.seed};\n  }\n}\nserialization.registerClass(RandomNormal);\n\nexport interface TruncatedNormalArgs {\n  /** Mean of the random values to generate. */\n  mean?: number;\n  /** Standard deviation of the random values to generate. */\n  stddev?: number;\n  /** Used to seed the random generator. */\n  seed?: number;\n}\n\nexport class TruncatedNormal extends Initializer {\n  /** @nocollapse */\n  static className = 'TruncatedNormal';\n\n  readonly DEFAULT_MEAN = 0.;\n  readonly DEFAULT_STDDEV = 0.05;\n  private mean: number;\n  private stddev: number;\n  private seed: number;\n\n  constructor(args: TruncatedNormalArgs) {\n    super();\n    this.mean = args.mean || this.DEFAULT_MEAN;\n    this.stddev = args.stddev || this.DEFAULT_STDDEV;\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    dtype = dtype || 'float32';\n    if (dtype !== 'float32' && dtype !== 'int32') {\n      throw new NotImplementedError(\n          `truncatedNormal does not support dType ${dtype}.`);\n    }\n    return truncatedNormal(shape, this.mean, this.stddev, dtype, this.seed);\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    return {mean: this.mean, stddev: this.stddev, seed: this.seed};\n  }\n}\nserialization.registerClass(TruncatedNormal);\n\nexport interface IdentityArgs {\n  /**\n   * Multiplicative factor to apply to the identity matrix.\n   */\n  gain?: number;\n}\n\nexport class Identity extends Initializer {\n  /** @nocollapse */\n  static className = 'Identity';\n  private gain: number;\n  constructor(args: IdentityArgs) {\n    super();\n    this.gain = args.gain != null ? args.gain : 1.0;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return tidy(() => {\n      if (shape.length !== 2 || shape[0] !== shape[1]) {\n        throw new ValueError(\n            'Identity matrix initializer can only be used for' +\n            ' 2D square matrices.');\n      } else {\n        return mul(this.gain, eye(shape[0]));\n      }\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    return {gain: this.gain};\n  }\n}\nserialization.registerClass(Identity);\n\n/**\n * Computes the number of input and output units for a weight shape.\n * @param shape Shape of weight.\n * @param dataFormat data format to use for convolution kernels.\n *   Note that all kernels in Keras are standardized on the\n *   CHANNEL_LAST ordering (even when inputs are set to CHANNEL_FIRST).\n * @return An length-2 array: fanIn, fanOut.\n */\nfunction computeFans(\n    shape: Shape, dataFormat: DataFormat = 'channelsLast'): number[] {\n  let fanIn: number;\n  let fanOut: number;\n  checkDataFormat(dataFormat);\n  if (shape.length === 2) {\n    fanIn = shape[0];\n    fanOut = shape[1];\n  } else if ([3, 4, 5].indexOf(shape.length) !== -1) {\n    if (dataFormat === 'channelsFirst') {\n      const receptiveFieldSize = arrayProd(shape, 2);\n      fanIn = shape[1] * receptiveFieldSize;\n      fanOut = shape[0] * receptiveFieldSize;\n    } else if (dataFormat === 'channelsLast') {\n      const receptiveFieldSize = arrayProd(shape, 0, shape.length - 2);\n      fanIn = shape[shape.length - 2] * receptiveFieldSize;\n      fanOut = shape[shape.length - 1] * receptiveFieldSize;\n    }\n  } else {\n    const shapeProd = arrayProd(shape);\n    fanIn = Math.sqrt(shapeProd);\n    fanOut = Math.sqrt(shapeProd);\n  }\n\n  return [fanIn, fanOut];\n}\n\nexport interface VarianceScalingArgs {\n  /** Scaling factor (positive float). */\n  scale?: number;\n\n  /** Fanning mode for inputs and outputs. */\n  mode?: FanMode;\n\n  /** Probabilistic distribution of the values. */\n  distribution?: Distribution;\n\n  /** Random number generator seed. */\n  seed?: number;\n}\n\nexport class VarianceScaling extends Initializer {\n  /** @nocollapse */\n  static className = 'VarianceScaling';\n  private scale: number;\n  private mode: FanMode;\n  private distribution: Distribution;\n  private seed: number;\n\n  /**\n   * Constructor of VarianceScaling.\n   * @throws ValueError for invalid value in scale.\n   */\n  constructor(args: VarianceScalingArgs) {\n    super();\n    if (args.scale < 0.0) {\n      throw new ValueError(\n          `scale must be a positive float. Got: ${args.scale}`);\n    }\n    this.scale = args.scale == null ? 1.0 : args.scale;\n    this.mode = args.mode == null ? 'fanIn' : args.mode;\n    checkFanMode(this.mode);\n    this.distribution =\n        args.distribution == null ? 'normal' : args.distribution;\n    checkDistribution(this.distribution);\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    const fans = computeFans(shape);\n    const fanIn = fans[0];\n    const fanOut = fans[1];\n    let scale = this.scale;\n    if (this.mode === 'fanIn') {\n      scale /= Math.max(1, fanIn);\n    } else if (this.mode === 'fanOut') {\n      scale /= Math.max(1, fanOut);\n    } else {\n      scale /= Math.max(1, (fanIn + fanOut) / 2);\n    }\n\n    if (this.distribution === 'normal') {\n      const stddev = Math.sqrt(scale);\n      dtype = dtype || 'float32';\n      if (dtype !== 'float32' && dtype !== 'int32') {\n        throw new NotImplementedError(\n            `${this.getClassName()} does not support dType ${dtype}.`);\n      }\n      return truncatedNormal(shape, 0, stddev, dtype, this.seed);\n    } else {\n      const limit = Math.sqrt(3 * scale);\n      return randomUniform(shape, -limit, limit, dtype, this.seed);\n    }\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    return {\n      scale: this.scale,\n      mode: this.mode,\n      distribution: this.distribution,\n      seed: this.seed\n    };\n  }\n}\nserialization.registerClass(VarianceScaling);\n\nexport interface SeedOnlyInitializerArgs {\n  /** Random number generator seed. */\n  seed?: number;\n}\n\nexport class GlorotUniform extends VarianceScaling {\n  /** @nocollapse */\n  static override className = 'GlorotUniform';\n\n  /**\n   * Constructor of GlorotUniform\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  override getClassName(): string {\n    // In Python Keras, GlorotUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(GlorotUniform);\n\nexport class GlorotNormal extends VarianceScaling {\n  /** @nocollapse */\n  static override className = 'GlorotNormal';\n\n  /**\n   * Constructor of GlorotNormal.\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  override getClassName(): string {\n    // In Python Keras, GlorotNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(GlorotNormal);\n\nexport class HeNormal extends VarianceScaling {\n  /** @nocollapse */\n  static override className = 'HeNormal';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  override getClassName(): string {\n    // In Python Keras, HeNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(HeNormal);\n\nexport class HeUniform extends VarianceScaling {\n  /** @nocollapse */\n  static override className = 'HeUniform';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  override getClassName(): string {\n    // In Python Keras, HeUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(HeUniform);\n\nexport class LeCunNormal extends VarianceScaling {\n  /** @nocollapse */\n  static override className = 'LeCunNormal';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  override getClassName(): string {\n    // In Python Keras, LeCunNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(LeCunNormal);\n\nexport class LeCunUniform extends VarianceScaling {\n  /** @nocollapse */\n  static override className = 'LeCunUniform';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  override getClassName(): string {\n    // In Python Keras, LeCunUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(LeCunUniform);\n\nexport interface OrthogonalArgs extends SeedOnlyInitializerArgs {\n  /**\n   * Multiplicative factor to apply to the orthogonal matrix. Defaults to 1.\n   */\n  gain?: number;\n}\n\nexport class Orthogonal extends Initializer {\n  /** @nocollapse */\n  static className = 'Orthogonal';\n  readonly DEFAULT_GAIN = 1;\n  protected readonly gain: number;\n  protected readonly seed: number;\n\n  constructor(args?: OrthogonalArgs) {\n    super();\n    this.gain = args.gain == null ? this.DEFAULT_GAIN : args.gain;\n    this.seed = args.seed;\n\n    if (this.seed != null) {\n      throw new NotImplementedError(\n          'Random seed is not implemented for Orthogonal Initializer yet.');\n    }\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return tidy(() => {\n      if (shape.length < 2) {\n        throw new NotImplementedError('Shape must be at least 2D.');\n      }\n      if (shape[0] * shape[1] > 2000) {\n        console.warn(\n            `Orthogonal initializer is being called on a matrix with more ` +\n            `than 2000 (${shape[0] * shape[1]}) elements: ` +\n            `Slowness may result.`);\n      }\n\n      // TODO(cais): Add seed support.\n      const normalizedShape =\n          shape[0] > shape[1] ? [shape[1], shape[0]] : shape;\n      const a = K.randomNormal(normalizedShape, 0, 1, 'float32') as Tensor2D;\n      let q = linalg.gramSchmidt(a) as Tensor2D;\n      if (shape[0] > shape[1]) {\n        q = transpose(q);\n      }\n      return mul(this.gain, q);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    return {\n      gain: this.gain,\n      seed: this.seed,\n    };\n  }\n}\nserialization.registerClass(Orthogonal);\n\n/** @docinline */\nexport type InitializerIdentifier =\n    'constant'|'glorotNormal'|'glorotUniform'|'heNormal'|'heUniform'|'identity'|\n    'leCunNormal'|'leCunUniform'|'ones'|'orthogonal'|'randomNormal'|\n    'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string;\n\n// Maps the JavaScript-like identifier keys to the corresponding registry\n// symbols.\nexport const INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP:\n    {[identifier in InitializerIdentifier]: string} = {\n      'constant': 'Constant',\n      'glorotNormal': 'GlorotNormal',\n      'glorotUniform': 'GlorotUniform',\n      'heNormal': 'HeNormal',\n      'heUniform': 'HeUniform',\n      'identity': 'Identity',\n      'leCunNormal': 'LeCunNormal',\n      'leCunUniform': 'LeCunUniform',\n      'ones': 'Ones',\n      'orthogonal': 'Orthogonal',\n      'randomNormal': 'RandomNormal',\n      'randomUniform': 'RandomUniform',\n      'truncatedNormal': 'TruncatedNormal',\n      'varianceScaling': 'VarianceScaling',\n      'zeros': 'Zeros'\n    };\n\nfunction deserializeInitializer(\n    config: serialization.ConfigDict,\n    customObjects: serialization.ConfigDict = {}): Initializer {\n  return deserializeKerasObject(\n      config, serialization.SerializationMap.getMap().classNameMap,\n      customObjects, 'initializer');\n}\n\nexport function serializeInitializer(initializer: Initializer):\n    serialization.ConfigDictValue {\n  return serializeKerasObject(initializer);\n}\n\nexport function getInitializer(identifier: InitializerIdentifier|Initializer|\n                               serialization.ConfigDict): Initializer {\n  if (typeof identifier === 'string') {\n    const className = identifier in INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ?\n        INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] :\n        identifier;\n    /* We have four 'helper' classes for common initializers that\n    all get serialized as 'VarianceScaling' and shouldn't go through\n    the deserializeInitializer pathway. */\n    if (className === 'GlorotNormal') {\n      return new GlorotNormal();\n    } else if (className === 'GlorotUniform') {\n      return new GlorotUniform();\n    } else if (className === 'HeNormal') {\n      return new HeNormal();\n    } else if (className === 'HeUniform') {\n      return new HeUniform();\n    } else if (className === 'LeCunNormal') {\n      return new LeCunNormal();\n    } else if (className === 'LeCunUniform') {\n      return new LeCunUniform();\n    } else {\n      const config: serialization.ConfigDict = {};\n      config['className'] = className;\n      config['config'] = {};\n      return deserializeInitializer(config);\n    }\n  } else if (identifier instanceof Initializer) {\n    return identifier;\n  } else {\n    return deserializeInitializer(identifier);\n  }\n}\n"]},"metadata":{},"sourceType":"module","externalDependencies":[]}