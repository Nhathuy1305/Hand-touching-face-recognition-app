{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Tile } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { clone } from './clone';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Broadcast an array to a compatible shape NumPy-style.\n *\n * The tensor's shape is compared to the broadcast shape from end to beginning.\n * Ones are prepended to the tensor's shape until it has the same length as\n * the broadcast shape. If input.shape[i]==shape[i], the (i+1)-th axis is\n * already broadcast-compatible. If input.shape[i]==1 and shape[i]==N, then\n * the input tensor is tiled N times along that axis (using tf.tile).\n *\n * @param input The tensor that is to be broadcasted.\n * @param shape The input is to be broadcast to this shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction broadcastTo_(x, shape) {\n  let input = convertToTensor(x, 'broadcastTo', 'x');\n  const xShape = input.shape;\n  if (shape.some(d => !(d > 0) || d % 1 !== 0)) {\n    throw new Error(`broadcastTo(): Invalid broadcast shape [${shape}].`);\n  }\n  if (shape.length < input.rank) {\n    throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${input.rank}.`);\n  }\n  if (shape.length > input.rank) {\n    const newShape = input.shape.slice();\n    while (newShape.length < shape.length) {\n      newShape.unshift(1);\n    }\n    input = reshape(input, newShape);\n  }\n  const inputShape = input.shape;\n  const reps = Array.from(shape);\n  for (let i = shape.length - 1; i >= 0; i--) {\n    if (inputShape[i] === shape[i]) {\n      reps[i] = 1;\n    } else if (input.shape[i] !== 1) {\n      throw new Error(`broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);\n    }\n  }\n  const axes = reps.map((n, i) => n > 1 ? i : -1).filter(i => i >= 0);\n  if (axes.length === 0) {\n    return clone(input);\n  }\n  // TODO call broadcastTo kernel directly once backends implement broadcstTo\n  const inputs = {\n    x: input\n  };\n  const attrs = {\n    reps\n  };\n  return ENGINE.runKernel(Tile, inputs, attrs);\n}\nexport const broadcastTo = op({\n  broadcastTo_\n});","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,MAAM,QAAO,WAAW;AAChC,SAAQC,IAAI,QAA8B,iBAAiB;AAI3D,SAAQC,eAAe,QAAO,oBAAoB;AAGlD,SAAQC,KAAK,QAAO,SAAS;AAC7B,SAAQC,EAAE,QAAO,aAAa;AAC9B,SAAQC,OAAO,QAAO,WAAW;AAEjC;;;;;;;;;;;;;;AAcA,SAASC,YAAY,CACjBC,CAAoB,EAAEC,KAAkB;EAC1C,IAAIC,KAAK,GAAGP,eAAe,CAACK,CAAC,EAAE,aAAa,EAAE,GAAG,CAAC;EAClD,MAAMG,MAAM,GAAGD,KAAK,CAACD,KAAK;EAE1B,IAAIA,KAAK,CAACG,IAAI,CAACC,CAAC,IAAI,EAAEA,CAAC,GAAG,CAAC,CAAC,IAAIA,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,EAAE;IAC5C,MAAM,IAAIC,KAAK,CAAC,2CAA2CL,KAAK,IAAI,CAAC;;EAGvE,IAAIA,KAAK,CAACM,MAAM,GAAGL,KAAK,CAACM,IAAI,EAAE;IAC7B,MAAM,IAAIF,KAAK,CAAC,+BAA+BL,KAAK,CAACM,MAAM,iBACvDL,KAAK,CAACM,IAAI,GAAG,CAAC;;EAGpB,IAAIP,KAAK,CAACM,MAAM,GAAGL,KAAK,CAACM,IAAI,EAAE;IAC7B,MAAMC,QAAQ,GAAGP,KAAK,CAACD,KAAK,CAACS,KAAK,EAAE;IACpC,OAAOD,QAAQ,CAACF,MAAM,GAAGN,KAAK,CAACM,MAAM,EAAE;MACrCE,QAAQ,CAACE,OAAO,CAAC,CAAC,CAAC;;IAErBT,KAAK,GAAGJ,OAAO,CAACI,KAAK,EAAEO,QAAQ,CAAC;;EAGlC,MAAMG,UAAU,GAAGV,KAAK,CAACD,KAAK;EAC9B,MAAMY,IAAI,GAAaC,KAAK,CAACC,IAAI,CAACd,KAAK,CAAC;EACxC,KAAK,IAAIe,CAAC,GAAGf,KAAK,CAACM,MAAM,GAAG,CAAC,EAAES,CAAC,IAAI,CAAC,EAAEA,CAAC,EAAE,EAAE;IAC1C,IAAIJ,UAAU,CAACI,CAAC,CAAC,KAAKf,KAAK,CAACe,CAAC,CAAC,EAAE;MAC9BH,IAAI,CAACG,CAAC,CAAC,GAAG,CAAC;KACZ,MAAM,IAAId,KAAK,CAACD,KAAK,CAACe,CAAC,CAAC,KAAK,CAAC,EAAE;MAC/B,MAAM,IAAIV,KAAK,CACX,mBAAmBH,MAAM,6BAA6BF,KAAK,IAAI,CAAC;;;EAGxE,MAAMgB,IAAI,GAAGJ,IAAI,CAACK,GAAG,CAAC,CAACC,CAAC,EAAEH,CAAC,KAAKG,CAAC,GAAG,CAAC,GAAGH,CAAC,GAAG,CAAC,CAAC,CAAC,CAACI,MAAM,CAACJ,CAAC,IAAIA,CAAC,IAAI,CAAC,CAAC;EAEnE,IAAIC,IAAI,CAACV,MAAM,KAAK,CAAC,EAAE;IACrB,OAAOX,KAAK,CAACM,KAAK,CAAc;;EAGlC;EACA,MAAMmB,MAAM,GAAe;IAACrB,CAAC,EAAEE;EAAK,CAAC;EACrC,MAAMoB,KAAK,GAAc;IAACT;EAAI,CAAC;EAC/B,OAAOpB,MAAM,CAAC8B,SAAS,CACnB7B,IAAI,EAAE2B,MAA8B,EAAEC,KAAgC,CAAC;AAC7E;AAEA,OAAO,MAAME,WAAW,GAAG3B,EAAE,CAAC;EAACE;AAAY,CAAC,CAAC","names":["ENGINE","Tile","convertToTensor","clone","op","reshape","broadcastTo_","x","shape","input","xShape","some","d","Error","length","rank","newShape","slice","unshift","inputShape","reps","Array","from","i","axes","map","n","filter","inputs","attrs","runKernel","broadcastTo"],"sources":["D:\\Do not touch hand on your face\\tfjs-core\\src\\ops\\broadcast_to.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Tile, TileAttrs, TileInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {Rank, ShapeMap, TensorLike} from '../types';\n\nimport {clone} from './clone';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Broadcast an array to a compatible shape NumPy-style.\n *\n * The tensor's shape is compared to the broadcast shape from end to beginning.\n * Ones are prepended to the tensor's shape until it has the same length as\n * the broadcast shape. If input.shape[i]==shape[i], the (i+1)-th axis is\n * already broadcast-compatible. If input.shape[i]==1 and shape[i]==N, then\n * the input tensor is tiled N times along that axis (using tf.tile).\n *\n * @param input The tensor that is to be broadcasted.\n * @param shape The input is to be broadcast to this shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction broadcastTo_<R extends Rank>(\n    x: Tensor|TensorLike, shape: ShapeMap[R]): Tensor<R> {\n  let input = convertToTensor(x, 'broadcastTo', 'x');\n  const xShape = input.shape;\n\n  if (shape.some(d => !(d > 0) || d % 1 !== 0)) {\n    throw new Error(`broadcastTo(): Invalid broadcast shape [${shape}].`);\n  }\n\n  if (shape.length < input.rank) {\n    throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${\n        input.rank}.`);\n  }\n\n  if (shape.length > input.rank) {\n    const newShape = input.shape.slice();\n    while (newShape.length < shape.length) {\n      newShape.unshift(1);\n    }\n    input = reshape(input, newShape);\n  }\n\n  const inputShape = input.shape;\n  const reps: number[] = Array.from(shape);\n  for (let i = shape.length - 1; i >= 0; i--) {\n    if (inputShape[i] === shape[i]) {\n      reps[i] = 1;\n    } else if (input.shape[i] !== 1) {\n      throw new Error(\n          `broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);\n    }\n  }\n  const axes = reps.map((n, i) => n > 1 ? i : -1).filter(i => i >= 0);\n\n  if (axes.length === 0) {\n    return clone(input) as Tensor<R>;\n  }\n\n  // TODO call broadcastTo kernel directly once backends implement broadcstTo\n  const inputs: TileInputs = {x: input};\n  const attrs: TileAttrs = {reps};\n  return ENGINE.runKernel(\n      Tile, inputs as {} as NamedTensorMap, attrs as unknown as NamedAttrMap);\n}\n\nexport const broadcastTo = op({broadcastTo_});\n"]},"metadata":{},"sourceType":"module","externalDependencies":[]}